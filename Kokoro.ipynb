{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90d3d793094545418d359e3dbe16eaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c227ca8ff6cc4e96b15d76526623df14",
              "IPY_MODEL_c0f3f6f102cb41aebdb023f83869b420",
              "IPY_MODEL_3d9df13c8aae4bd9a048a5bbcbff8d7b"
            ],
            "layout": "IPY_MODEL_1d7c10e76e9e4e1fbc7de212a3cd783c"
          }
        },
        "c227ca8ff6cc4e96b15d76526623df14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3aaf907db424beb818b54725a8ec143",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2d8b8543944959b353e201ce13a91d",
            "value": "Validating audio samples: 100%"
          }
        },
        "c0f3f6f102cb41aebdb023f83869b420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2be08bb3f24472969309f1022dc4c2",
            "max": 22827,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43d71456d1be4f9ab453461735c9465e",
            "value": 22827
          }
        },
        "3d9df13c8aae4bd9a048a5bbcbff8d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01cf7f59069747ef88df4266102e4632",
            "placeholder": "​",
            "style": "IPY_MODEL_dcaf4d1bba124d0d917a36870f1b96fe",
            "value": " 22827/22827 [00:09&lt;00:00, 2373.73file/s]"
          }
        },
        "1d7c10e76e9e4e1fbc7de212a3cd783c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3aaf907db424beb818b54725a8ec143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2d8b8543944959b353e201ce13a91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b2be08bb3f24472969309f1022dc4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d71456d1be4f9ab453461735c9465e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01cf7f59069747ef88df4266102e4632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcaf4d1bba124d0d917a36870f1b96fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ed1190a611a44ae9198f4206531a5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8177784afcbb46eabac596d22cf1401d",
              "IPY_MODEL_7c41ce5340ec4082a3d1bf3bf904c889",
              "IPY_MODEL_76e7a8b3acc947febb6190c60d5656fb"
            ],
            "layout": "IPY_MODEL_837d5ca6797e4d3da1ef3cb6fa5be42c"
          }
        },
        "8177784afcbb46eabac596d22cf1401d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515ef5b1b92f4c82a81386444e9df53e",
            "placeholder": "​",
            "style": "IPY_MODEL_00259f9482354ed7ad9b81db8cc78eab",
            "value": "Loading batches:   0%"
          }
        },
        "7c41ce5340ec4082a3d1bf3bf904c889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de92446295540da99f213a5c37549d5",
            "max": 11407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d316a905df444b1681fab63d47e17baa",
            "value": 4
          }
        },
        "76e7a8b3acc947febb6190c60d5656fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5936221a871e452e9e03b5a681f97975",
            "placeholder": "​",
            "style": "IPY_MODEL_a5f90ac2317f4ac28a23ab44120ea932",
            "value": " 4/11407 [00:13&lt;8:23:41,  2.65s/batch]"
          }
        },
        "837d5ca6797e4d3da1ef3cb6fa5be42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515ef5b1b92f4c82a81386444e9df53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00259f9482354ed7ad9b81db8cc78eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1de92446295540da99f213a5c37549d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d316a905df444b1681fab63d47e17baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5936221a871e452e9e03b5a681f97975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f90ac2317f4ac28a23ab44120ea932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21a35ad3802c4772ab9d5d7b48b7fde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_518150ab35f7434893f01f947ac0470a",
              "IPY_MODEL_19328187c6d84018b0c2a7f129e6f946",
              "IPY_MODEL_95cb0a04482f4bb2aad8d7ed867a9a96"
            ],
            "layout": "IPY_MODEL_2f442a105b654f2598db20593f685b94"
          }
        },
        "518150ab35f7434893f01f947ac0470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb534db8f35d42118e42825215f19502",
            "placeholder": "​",
            "style": "IPY_MODEL_3ad9e110f03e4cf790cbf0d828693080",
            "value": "Processing texts: 100%"
          }
        },
        "19328187c6d84018b0c2a7f129e6f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647a948d12d6439eacc0386bbfd10fcc",
            "max": 22814,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a986c831ef9c4a968a93491e22fe29a5",
            "value": 22814
          }
        },
        "95cb0a04482f4bb2aad8d7ed867a9a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e454b054244cff8cab45a26396a657",
            "placeholder": "​",
            "style": "IPY_MODEL_145b8896c1e14e358f69da83bd665245",
            "value": " 22814/22814 [00:00&lt;00:00, 45562.34it/s]"
          }
        },
        "2f442a105b654f2598db20593f685b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb534db8f35d42118e42825215f19502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad9e110f03e4cf790cbf0d828693080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "647a948d12d6439eacc0386bbfd10fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a986c831ef9c4a968a93491e22fe29a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24e454b054244cff8cab45a26396a657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145b8896c1e14e358f69da83bd665245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a591274903ca485c9a628cec8e8ded49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_520f2587cb6748e68003891922863897",
              "IPY_MODEL_235cb80d63364dcf86d24b9cbc075f02",
              "IPY_MODEL_66b8c42d4d594d15806ef13d9e09b91c"
            ],
            "layout": "IPY_MODEL_af4753da20644b07a23f7480d3d95af1"
          }
        },
        "520f2587cb6748e68003891922863897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6bc610a8ddd42de8faa80e4a8e9bb27",
            "placeholder": "​",
            "style": "IPY_MODEL_81655834adcf48049f09e5cc19fd16b9",
            "value": "Training Progress:   0%"
          }
        },
        "235cb80d63364dcf86d24b9cbc075f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5bc67cb0cb34bb9b1c37b4ef13e5af6",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f5fffb8b8c04c9f85a225f045664530",
            "value": 0
          }
        },
        "66b8c42d4d594d15806ef13d9e09b91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c27a8a693b44819f2d32588dbb0312",
            "placeholder": "​",
            "style": "IPY_MODEL_1cf9fc8430a247fa901349fa5f15aa77",
            "value": " 0/10 [3:56:41&lt;?, ?epoch/s]"
          }
        },
        "af4753da20644b07a23f7480d3d95af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bc610a8ddd42de8faa80e4a8e9bb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81655834adcf48049f09e5cc19fd16b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5bc67cb0cb34bb9b1c37b4ef13e5af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5fffb8b8c04c9f85a225f045664530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52c27a8a693b44819f2d32588dbb0312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf9fc8430a247fa901349fa5f15aa77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a2551c4ba344f3895c08235801f0775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0269cd2d99b44bcda0400a1c7bc1c05c",
              "IPY_MODEL_e39b6f9de7ed46828a77cdc2125d9344",
              "IPY_MODEL_e121545903fc47d988dc0562ff75c06e"
            ],
            "layout": "IPY_MODEL_ef21564b5e4f4f51acc6b4cc2e096f45"
          }
        },
        "0269cd2d99b44bcda0400a1c7bc1c05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f392f3dd7ebb4450b6322cb02e04b515",
            "placeholder": "​",
            "style": "IPY_MODEL_d66f8b509e2f48728d54dfd2ceedb74e",
            "value": "Epoch 1:  49%"
          }
        },
        "e39b6f9de7ed46828a77cdc2125d9344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40fdb29335244c11a48445995941f968",
            "max": 11407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3c8e8585e8f41bfa775080af4547739",
            "value": 5614
          }
        },
        "e121545903fc47d988dc0562ff75c06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b3ecd01ff8469c9191ff210fed4f93",
            "placeholder": "​",
            "style": "IPY_MODEL_897ed3873a1e404a850ea1b540b41376",
            "value": " 5614/11407 [4:00:32&lt;4:10:21,  2.59s/batch, Loss=24.0547, Step=5582]"
          }
        },
        "ef21564b5e4f4f51acc6b4cc2e096f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f392f3dd7ebb4450b6322cb02e04b515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d66f8b509e2f48728d54dfd2ceedb74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40fdb29335244c11a48445995941f968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c8e8585e8f41bfa775080af4547739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64b3ecd01ff8469c9191ff210fed4f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897ed3873a1e404a850ea1b540b41376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarakatPay/kokoro-pashto-tts-experiments/blob/main/Kokoro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "883cbe88",
        "outputId": "4442706c-6b4a-4471-88f5-3aeeb88bc9a0"
      },
      "source": [
        "# Re-run the installation steps with explicit uninstallation\n",
        "!pip uninstall numpy librosa numba -y\n",
        "!pip install \"numpy==1.24.3\"\n",
        "!pip install \"numba==0.59.1\"\n",
        "!pip install \"librosa==0.10.1\"\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets accelerate\n",
        "!pip install soundfile phonemizer wandb tensorboard tqdm\n",
        "\n",
        "print(\"CRITICAL: Go to Runtime -> Restart Runtime NOW, then run from Cell 2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: librosa 0.11.0\n",
            "Uninstalling librosa-0.11.0:\n",
            "  Successfully uninstalled librosa-0.11.0\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.48.0 requires numba>=0.54, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "stumpy 1.13.0 requires numba>=0.57.1, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires numba>=0.51.2, which is not installed.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9dd28c2c9df84209988603bd585fcbab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numba==0.59.1\n",
            "  Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba==0.59.1)\n",
            "  Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba==0.59.1) (1.24.3)\n",
            "Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "Successfully installed llvmlite-0.42.0 numba-0.59.1\n",
            "Collecting librosa==0.10.1\n",
            "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.59.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (4.14.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa==0.10.1) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa==0.10.1) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa==0.10.1) (0.42.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.10.1) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa==0.10.1) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.1) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa==0.10.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2025.7.9)\n",
            "Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: librosa\n",
            "Successfully installed librosa-0.10.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cell 1: Complete Environment Reset\n",
        "# !pip uninstall numpy librosa numba -y\n",
        "# !pip install \"numpy==1.24.3\"\n",
        "# !pip install \"numba==0.59.1\"\n",
        "# !pip install \"librosa==0.10.1\"\n",
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install transformers datasets accelerate\n",
        "# !pip install soundfile phonemizer wandb tensorboard tqdm\n",
        "\n",
        "# print(\"CRITICAL: Go to Runtime -> Restart Runtime NOW, then run from Cell 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "collapsed": true,
        "id": "PSdOKobDm_rh",
        "outputId": "8f0c2094-ef9a-4338-b971-9760acdba56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: librosa 0.11.0\n",
            "Uninstalling librosa-0.11.0:\n",
            "  Successfully uninstalled librosa-0.11.0\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.48.0 requires numba>=0.54, which is not installed.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "stumpy 1.13.0 requires numba>=0.57.1, which is not installed.\n",
            "umap-learn 0.5.9.post2 requires numba>=0.51.2, which is not installed.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, which is not installed.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "65a1166e504c434bb057e0346ac596f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numba==0.59.1\n",
            "  Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba==0.59.1)\n",
            "  Downloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba==0.59.1) (1.24.3)\n",
            "Downloading numba-0.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.42.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb594592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05e82b9-5eb2-4546-c86f-0e78b7bd442e"
      },
      "source": [
        "# Cell 2: Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from accelerate import Accelerator\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Verify versions\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Librosa version: {librosa.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.24.3\n",
            "Librosa version: 0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrCtogGKPHQk",
        "outputId": "3a5309a5-fe78-4b4f-e39c-919ae430a5ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Configuration\n",
        "class Config:\n",
        "    # Dataset paths\n",
        "    DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "    AUDIO_FOLDER = \"/content/drive/MyDrive/Mangal_Paktika_Audios\"\n",
        "    JSON_FILE = \"/content/drive/MyDrive/mangal_paktika_entries.json\"\n",
        "    OUTPUT_DIR = f\"{DRIVE_PATH}/kokoro_pashto_models\"\n",
        "\n",
        "    # Model configuration\n",
        "    MODEL_NAME = \"hexgrad/Kokoro-82M\"\n",
        "    SAMPLE_RATE = 22050\n",
        "    N_MELS = 80\n",
        "    HOP_LENGTH = 256\n",
        "    WIN_LENGTH = 1024\n",
        "    N_FFT = 1024\n",
        "\n",
        "    # Training configuration\n",
        "    BATCH_SIZE = 2  # Reduced from 4 to avoid memory issues\n",
        "    LEARNING_RATE = 1e-4\n",
        "    NUM_EPOCHS = 50\n",
        "    GRADIENT_ACCUMULATION_STEPS = 4\n",
        "    MAX_GRAD_NORM = 1.0\n",
        "\n",
        "    # Audio processing\n",
        "    MAX_AUDIO_LENGTH = 10.0  # seconds\n",
        "    MIN_AUDIO_LENGTH = 1.0   # seconds\n",
        "\n",
        "    # Sequence length configuration (NEW)\n",
        "    MAX_TEXT_LENGTH = 100    # Maximum words in input text\n",
        "    TARGET_MEL_LENGTH = 800  # Target mel spectrogram frames\n",
        "    MIN_MEL_LENGTH = 50      # Minimum mel frames to keep sample\n",
        "\n",
        "    # Model architecture (NEW)\n",
        "    D_MODEL = 512           # Transformer hidden dimension\n",
        "    N_HEADS = 8             # Number of attention heads\n",
        "    N_LAYERS = 6            # Number of transformer layers\n",
        "    UPSAMPLE_FACTOR = 8     # How much to upsample text to mel ratio\n",
        "\n",
        "    # Device\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "Z5OZ04XONtsA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7agy7Kn86dy_",
        "outputId": "a2b8ff59-b1a7-4838-816d-a4869ffa28a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Create Output Directories\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{config.OUTPUT_DIR}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{config.OUTPUT_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "print(f\"Using device: {config.DEVICE}\")\n",
        "print(f\"Audio folder: {config.AUDIO_FOLDER}\")\n",
        "print(f\"JSON file: {config.JSON_FILE}\")\n",
        "print(f\"Output directory: {config.OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "1LJgpGthNx_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38a6be1-c58a-43f8-f900-598ee221475c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Audio folder: /content/drive/MyDrive/Mangal_Paktika_Audios\n",
            "JSON file: /content/drive/MyDrive/mangal_paktika_entries.json\n",
            "Output directory: /content/drive/MyDrive/kokoro_pashto_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Audio Processing Functions\n",
        "def load_audio(file_path: str, sample_rate: int = 22050) -> torch.Tensor:\n",
        "    \"\"\"Load audio file and convert to tensor\"\"\"\n",
        "    try:\n",
        "        # Use soundfile instead of librosa for loading\n",
        "        audio, sr = sf.read(file_path)\n",
        "\n",
        "        # Resample if needed using torchaudio\n",
        "        if sr != sample_rate:\n",
        "            audio_tensor = torch.FloatTensor(audio)\n",
        "            if len(audio_tensor.shape) > 1:\n",
        "                audio_tensor = audio_tensor.mean(dim=1)  # Convert to mono\n",
        "\n",
        "            # Resample using torchaudio\n",
        "            resampler = torchaudio.transforms.Resample(sr, sample_rate)\n",
        "            audio_tensor = resampler(audio_tensor)\n",
        "            return audio_tensor\n",
        "        else:\n",
        "            if len(audio.shape) > 1:\n",
        "                audio = audio.mean(axis=1)  # Convert to mono\n",
        "            return torch.FloatTensor(audio)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading audio {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_mel_spectrogram(audio: torch.Tensor,\n",
        "                          sample_rate: int = 22050,\n",
        "                          n_mels: int = 80,\n",
        "                          hop_length: int = 256,\n",
        "                          win_length: int = 1024,\n",
        "                          n_fft: int = 1024) -> torch.Tensor:\n",
        "    \"\"\"Extract mel spectrogram from audio\"\"\"\n",
        "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_mels=n_mels,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "        n_fft=n_fft,\n",
        "        power=2.0\n",
        "    )\n",
        "\n",
        "    mel_spec = mel_transform(audio)\n",
        "    mel_spec = torch.log(mel_spec + 1e-9)  # Log mel spectrogram\n",
        "    return mel_spec\n",
        "\n",
        "def download_audio(url: str, save_path: str) -> bool:\n",
        "    \"\"\"Download audio file from URL\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "jdhHxGPrN0ds"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Dataset Class (Alternative approach)\n",
        "class PashtoTTSDataset(Dataset):\n",
        "    def __init__(self, json_file_path: str, audio_folder: str):\n",
        "        self.json_file_path = json_file_path\n",
        "        self.audio_folder = audio_folder\n",
        "\n",
        "        # Load JSON data\n",
        "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        # Filter valid samples\n",
        "        self.valid_samples = []\n",
        "        self._prepare_dataset()\n",
        "\n",
        "    def _prepare_dataset(self):\n",
        "        \"\"\"Prepare dataset by validating audio files\"\"\"\n",
        "        print(f\"Preparing dataset from {self.json_file_path}\")\n",
        "\n",
        "        missing_count = 0\n",
        "        found_count = 0\n",
        "        file_errors = 0\n",
        "\n",
        "        for i, item in enumerate(tqdm(self.data, desc=\"Validating audio samples\", unit=\"file\")):\n",
        "            audio_file = item['file']\n",
        "            sentence = item['sentence']\n",
        "\n",
        "            # Create local audio path\n",
        "            audio_path = os.path.join(self.audio_folder, audio_file)\n",
        "\n",
        "            # Check if audio file exists\n",
        "            if not os.path.exists(audio_path):\n",
        "                missing_count += 1\n",
        "                continue\n",
        "\n",
        "            found_count += 1\n",
        "\n",
        "            try:\n",
        "                # Simple validation: check file size only\n",
        "                file_size = os.path.getsize(audio_path)\n",
        "                if file_size > 1000:  # Skip very small files\n",
        "                    # Skip duration check for now - validate during training\n",
        "                    self.valid_samples.append({\n",
        "                        'audio_path': audio_path,\n",
        "                        'text': sentence,\n",
        "                        'gender': item['gender'],\n",
        "                        'accent': item['accent'],\n",
        "                        'id': item['id']\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                file_errors += 1\n",
        "                if i < 5:\n",
        "                    print(f\"File error for {audio_file}: {e}\")\n",
        "\n",
        "        print(f\"\\nSummary:\")\n",
        "        print(f\"Files found: {found_count}\")\n",
        "        print(f\"Files missing: {missing_count}\")\n",
        "        print(f\"File errors: {file_errors}\")\n",
        "        print(f\"Valid samples: {len(self.valid_samples)}\")\n",
        "        print(\"Note: Duration validation will happen during training\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.valid_samples[idx]\n",
        "\n",
        "        # Load audio with duration validation here\n",
        "        audio = load_audio(sample['audio_path'], config.SAMPLE_RATE)\n",
        "\n",
        "        if audio is None:\n",
        "            # Return a dummy sample if audio fails to load\n",
        "            return None\n",
        "\n",
        "        # Check duration here during actual loading\n",
        "        audio_length = len(audio) / config.SAMPLE_RATE\n",
        "        if not (config.MIN_AUDIO_LENGTH <= audio_length <= config.MAX_AUDIO_LENGTH):\n",
        "            # Return None for invalid duration - DataLoader will skip\n",
        "            return None\n",
        "\n",
        "        # Extract mel spectrogram\n",
        "        mel_spec = extract_mel_spectrogram(\n",
        "            audio,\n",
        "            sample_rate=config.SAMPLE_RATE,\n",
        "            n_mels=config.N_MELS,\n",
        "            hop_length=config.HOP_LENGTH,\n",
        "            win_length=config.WIN_LENGTH,\n",
        "            n_fft=config.N_FFT\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'mel_spec': mel_spec,\n",
        "            'text': sample['text'],\n",
        "            'audio_length': len(audio),\n",
        "            'mel_length': mel_spec.shape[1],\n",
        "            'gender': sample['gender'],\n",
        "            'accent': sample['accent']\n",
        "        }"
      ],
      "metadata": {
        "id": "Tq3nVK7pN2pk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Collate Function\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for DataLoader\"\"\"\n",
        "    # Filter out None values\n",
        "    batch = [item for item in batch if item is not None]\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "\n",
        "    mel_specs = [item['mel_spec'] for item in batch]\n",
        "    texts = [item['text'] for item in batch]\n",
        "    audio_lengths = [item['audio_length'] for item in batch]\n",
        "    mel_lengths = [item['mel_length'] for item in batch]\n",
        "\n",
        "    # Pad mel spectrograms\n",
        "    max_mel_length = max(mel_lengths)\n",
        "    padded_mels = []\n",
        "\n",
        "    for mel in mel_specs:\n",
        "        if mel.shape[1] < max_mel_length:\n",
        "            padding = torch.zeros(mel.shape[0], max_mel_length - mel.shape[1])\n",
        "            padded_mel = torch.cat([mel, padding], dim=1)\n",
        "        else:\n",
        "            padded_mel = mel\n",
        "        padded_mels.append(padded_mel)\n",
        "\n",
        "    return {\n",
        "        'mel_specs': torch.stack(padded_mels),\n",
        "        'texts': texts,\n",
        "        'audio_lengths': torch.tensor(audio_lengths),\n",
        "        'mel_lengths': torch.tensor(mel_lengths)\n",
        "    }"
      ],
      "metadata": {
        "id": "kOrTqC05N5S6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Simple TTS Model Architecture\n",
        "class SimpleTTSModel(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model: int = 512, n_heads: int = 8,\n",
        "                 n_layers: int = 6, mel_dim: int = 80):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.mel_dim = mel_dim\n",
        "\n",
        "        # Text encoder\n",
        "        self.text_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model))\n",
        "\n",
        "        # Transformer layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Duration predictor\n",
        "        self.duration_predictor = nn.Linear(d_model, 1)\n",
        "\n",
        "        # Mel spectrogram decoder - simplified approach\n",
        "        self.mel_projection = nn.Linear(d_model, mel_dim)\n",
        "        self.output_projection = nn.Linear(mel_dim, mel_dim)\n",
        "\n",
        "        # Learnable expansion to create longer sequences\n",
        "        self.expand_factor = 4  # Each text token -> 4 mel frames\n",
        "        self.expansion_layer = nn.Linear(d_model, d_model * self.expand_factor)\n",
        "\n",
        "    def forward(self, text_tokens, mel_targets=None):\n",
        "        batch_size, text_len = text_tokens.shape\n",
        "\n",
        "        # Text encoding\n",
        "        text_emb = self.text_embedding(text_tokens)\n",
        "        seq_len = text_emb.size(1)\n",
        "        text_emb += self.pos_encoding[:seq_len].unsqueeze(0)\n",
        "\n",
        "        # Transformer encoding\n",
        "        encoded = self.transformer(text_emb)  # [batch, text_len, d_model]\n",
        "\n",
        "        # Duration prediction\n",
        "        durations = self.duration_predictor(encoded).squeeze(-1)\n",
        "        durations = torch.relu(durations)\n",
        "\n",
        "        # Expand sequence length\n",
        "        expanded = self.expansion_layer(encoded)  # [batch, text_len, d_model * expand_factor]\n",
        "        expanded = expanded.view(batch_size, text_len * self.expand_factor, self.d_model)\n",
        "\n",
        "        # Generate mel spectrograms\n",
        "        mel_hidden = self.mel_projection(expanded)  # [batch, expanded_len, mel_dim]\n",
        "        mel_output = self.output_projection(mel_hidden)  # [batch, expanded_len, mel_dim]\n",
        "\n",
        "        # Transpose to [batch, mel_dim, seq_len] for loss calculation\n",
        "        mel_output = mel_output.transpose(1, 2)\n",
        "\n",
        "        return {\n",
        "            'mel_output': mel_output,\n",
        "            'durations': durations,\n",
        "            'encoded': encoded\n",
        "        }"
      ],
      "metadata": {
        "id": "Gm5vC0S_N7Xd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Word-level Tokenizer\n",
        "import re\n",
        "\n",
        "class WordTokenizer:\n",
        "    def __init__(self):\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        self.vocab_size = 0\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and normalize Pashto text\"\"\"\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        # Normalize punctuation spacing\n",
        "        text = re.sub(r'([۔،؟!])', r' \\1 ', text)\n",
        "        text = re.sub(r'([.،؟!])', r' \\1 ', text)\n",
        "\n",
        "        # Clean up multiple spaces\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        return text\n",
        "\n",
        "    def tokenize_text(self, text: str) -> list:\n",
        "        \"\"\"Split text into words and punctuation\"\"\"\n",
        "        # Preprocess text\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        # Split by whitespace\n",
        "        tokens = text.split()\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def build_vocab(self, texts: List[str]):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        word_counts = {}\n",
        "\n",
        "        print(\"Analyzing text corpus...\")\n",
        "        for text in tqdm(texts, desc=\"Processing texts\"):\n",
        "            tokens = self.tokenize_text(text)\n",
        "            for token in tokens:\n",
        "                word_counts[token] = word_counts.get(token, 0) + 1\n",
        "\n",
        "        # Sort by frequency (most common first)\n",
        "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Add special tokens\n",
        "        special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
        "\n",
        "        # Create vocabulary\n",
        "        vocab_words = special_tokens.copy()\n",
        "\n",
        "        # Add words that appear at least 2 times (filter very rare words)\n",
        "        min_freq = 2\n",
        "        for word, count in sorted_words:\n",
        "            if count >= min_freq:\n",
        "                vocab_words.append(word)\n",
        "\n",
        "        # Create mappings\n",
        "        self.word_to_idx = {word: idx for idx, word in enumerate(vocab_words)}\n",
        "        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
        "        self.vocab_size = len(vocab_words)\n",
        "\n",
        "        # Print statistics\n",
        "        print(f\"\\nVocabulary Statistics:\")\n",
        "        print(f\"Total unique words in corpus: {len(word_counts)}\")\n",
        "        print(f\"Words with frequency >= {min_freq}: {len([w for w, c in sorted_words if c >= min_freq])}\")\n",
        "        print(f\"Final vocabulary size: {self.vocab_size}\")\n",
        "        print(f\"Most common words: {[word for word, _ in sorted_words[:20]]}\")\n",
        "        print(f\"Sample vocabulary: {vocab_words[:20]}\")\n",
        "\n",
        "        # Show frequency distribution\n",
        "        freq_dist = {}\n",
        "        for _, count in sorted_words:\n",
        "            freq_range = f\"{count//10*10}-{count//10*10+9}\"\n",
        "            freq_dist[freq_range] = freq_dist.get(freq_range, 0) + 1\n",
        "        print(f\"Frequency distribution: {dict(list(freq_dist.items())[:10])}\")\n",
        "\n",
        "    def encode(self, text: str, max_length: int = 50) -> torch.Tensor:\n",
        "        \"\"\"Encode text to tensor\"\"\"\n",
        "        tokens = self.tokenize_text(text)\n",
        "\n",
        "        # Convert words to indices\n",
        "        indices = []\n",
        "        for token in tokens:\n",
        "            if token in self.word_to_idx:\n",
        "                indices.append(self.word_to_idx[token])\n",
        "            else:\n",
        "                indices.append(self.word_to_idx['<unk>'])  # Unknown word\n",
        "\n",
        "        # Add start and end tokens\n",
        "        indices = [self.word_to_idx['<sos>']] + indices + [self.word_to_idx['<eos>']]\n",
        "\n",
        "        # Pad or truncate\n",
        "        if len(indices) > max_length:\n",
        "            indices = indices[:max_length]\n",
        "        else:\n",
        "            indices.extend([self.word_to_idx['<pad>']] * (max_length - len(indices)))\n",
        "\n",
        "        return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "    def decode(self, tokens: torch.Tensor) -> str:\n",
        "        \"\"\"Decode tensor to text\"\"\"\n",
        "        words = []\n",
        "        for token in tokens:\n",
        "            word = self.idx_to_word.get(token.item(), '')\n",
        "            if word not in ['<pad>', '<sos>', '<eos>']:\n",
        "                words.append(word)\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def get_vocab_info(self):\n",
        "        \"\"\"Get detailed vocabulary information\"\"\"\n",
        "        return {\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'special_tokens': ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
        "            'sample_words': list(self.word_to_idx.keys())[:50]\n",
        "        }"
      ],
      "metadata": {
        "id": "Bf7PYu-pN-NH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Training Function\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # Add progress bar for training batches\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")\n",
        "\n",
        "    successful_batches = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        mel_specs = batch['mel_specs'].to(device)\n",
        "        texts = batch['texts']\n",
        "        mel_lengths = batch['mel_lengths']\n",
        "\n",
        "        # Tokenize texts\n",
        "        text_tokens = []\n",
        "        for text in texts:\n",
        "            tokens = tokenizer.encode(text, max_length=config.MAX_TEXT_LENGTH)\n",
        "            text_tokens.append(tokens)\n",
        "\n",
        "        text_tokens = torch.stack(text_tokens).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(text_tokens, mel_specs)\n",
        "\n",
        "        # Get dimensions\n",
        "        batch_size, mel_dim, model_seq_len = outputs['mel_output'].shape\n",
        "        target_batch_size, target_mel_dim, target_seq_len = mel_specs.shape\n",
        "\n",
        "        # Handle sequence length mismatch - always use the SHORTER length\n",
        "        min_seq_len = min(model_seq_len, target_seq_len)\n",
        "\n",
        "        # Truncate both to the same length\n",
        "        model_output_adjusted = outputs['mel_output'][:, :, :min_seq_len]\n",
        "        mel_specs_adjusted = mel_specs[:, :, :min_seq_len]\n",
        "\n",
        "        # Skip if resulting sequence is too short\n",
        "        if min_seq_len < 10:\n",
        "            continue\n",
        "\n",
        "        # Calculate loss\n",
        "        try:\n",
        "            mel_loss = criterion(model_output_adjusted, mel_specs_adjusted)\n",
        "            duration_loss = torch.mean(torch.abs(outputs['durations']))\n",
        "\n",
        "            loss = mel_loss + 0.1 * duration_loss\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"Skipping batch {batch_idx} due to NaN/Inf loss\")\n",
        "                continue\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            successful_batches += 1\n",
        "\n",
        "            # Update progress bar with current loss\n",
        "            progress_bar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Mel Loss': f'{mel_loss.item():.4f}',\n",
        "                'Avg Loss': f'{total_loss/successful_batches:.4f}',\n",
        "                'Seq Len': f'{min_seq_len}'\n",
        "            })\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Skipping batch {batch_idx} due to error: {e}\")\n",
        "            continue\n",
        "\n",
        "    if successful_batches == 0:\n",
        "        print(\"Warning: No successful batches in this epoch!\")\n",
        "        return float('inf')\n",
        "\n",
        "    return total_loss / successful_batches"
      ],
      "metadata": {
        "id": "YAArn_AqOAe7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Load Dataset and Create DataLoader\n",
        "print(\"Loading Mangal Paktika dataset...\")\n",
        "dataset = PashtoTTSDataset(config.JSON_FILE, config.AUDIO_FOLDER)\n",
        "\n",
        "# Only create DataLoader if we have valid samples\n",
        "if len(dataset) > 0:\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDataset size: {len(dataset)}\")\n",
        "    print(f\"Number of batches: {len(dataloader)}\")\n",
        "\n",
        "    # Preview DataLoader with progress bar\n",
        "    print(\"\\nTesting DataLoader with progress indicator...\")\n",
        "    sample_count = 0\n",
        "    successful_batches = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Loading batches\", unit=\"batch\"):\n",
        "        if batch is not None:  # Handle None batches\n",
        "            sample_count += len(batch['texts'])\n",
        "            successful_batches += 1\n",
        "\n",
        "        # Only preview first 5 successful batches\n",
        "        if successful_batches >= 5:\n",
        "            break\n",
        "\n",
        "    print(f\"Successfully loaded {sample_count} samples in {successful_batches} batches\")\n",
        "else:\n",
        "    print(\"ERROR: No valid samples found! Cannot create DataLoader.\")"
      ],
      "metadata": {
        "id": "KEuGpFlcOC2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "90d3d793094545418d359e3dbe16eaae",
            "c227ca8ff6cc4e96b15d76526623df14",
            "c0f3f6f102cb41aebdb023f83869b420",
            "3d9df13c8aae4bd9a048a5bbcbff8d7b",
            "1d7c10e76e9e4e1fbc7de212a3cd783c",
            "f3aaf907db424beb818b54725a8ec143",
            "6f2d8b8543944959b353e201ce13a91d",
            "2b2be08bb3f24472969309f1022dc4c2",
            "43d71456d1be4f9ab453461735c9465e",
            "01cf7f59069747ef88df4266102e4632",
            "dcaf4d1bba124d0d917a36870f1b96fe",
            "9ed1190a611a44ae9198f4206531a5d0",
            "8177784afcbb46eabac596d22cf1401d",
            "7c41ce5340ec4082a3d1bf3bf904c889",
            "76e7a8b3acc947febb6190c60d5656fb",
            "837d5ca6797e4d3da1ef3cb6fa5be42c",
            "515ef5b1b92f4c82a81386444e9df53e",
            "00259f9482354ed7ad9b81db8cc78eab",
            "1de92446295540da99f213a5c37549d5",
            "d316a905df444b1681fab63d47e17baa",
            "5936221a871e452e9e03b5a681f97975",
            "a5f90ac2317f4ac28a23ab44120ea932"
          ]
        },
        "outputId": "d50fa1c8-4a7d-4265-9dc3-f98dd3bf04f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Mangal Paktika dataset...\n",
            "Preparing dataset from /content/drive/MyDrive/mangal_paktika_entries.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating audio samples:   0%|          | 0/22827 [00:00<?, ?file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d3d793094545418d359e3dbe16eaae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "Files found: 22819\n",
            "Files missing: 8\n",
            "File errors: 0\n",
            "Valid samples: 22814\n",
            "Note: Duration validation will happen during training\n",
            "\n",
            "Dataset size: 22814\n",
            "Number of batches: 11407\n",
            "\n",
            "Testing DataLoader with progress indicator...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading batches:   0%|          | 0/11407 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ed1190a611a44ae9198f4206531a5d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 10 samples in 5 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cell 13: Load Dataset and Create DataLoader\n",
        "# dataset = PashtoTTSDataset(selected_json)\n",
        "# dataloader = DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=config.BATCH_SIZE,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=collate_fn,\n",
        "#     num_workers=2\n",
        "# )\n",
        "\n",
        "# print(f\"Dataset size: {len(dataset)}\")\n",
        "# print(f\"Number of batches: {len(dataloader)}\")"
      ],
      "metadata": {
        "id": "0CT92GkhOEk9",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Initialize Word Tokenizer\n",
        "print(\"Building word-level vocabulary...\")\n",
        "all_texts = [item['text'] for item in dataset.valid_samples]\n",
        "\n",
        "tokenizer = WordTokenizer()\n",
        "tokenizer.build_vocab(all_texts)\n",
        "\n",
        "# Show sample encoding/decoding\n",
        "sample_text = all_texts[0]\n",
        "print(f\"\\nSample text: {sample_text}\")\n",
        "encoded = tokenizer.encode(sample_text)\n",
        "print(f\"Encoded: {encoded}\")\n",
        "decoded = tokenizer.decode(encoded)\n",
        "print(f\"Decoded: {decoded}\")\n",
        "\n",
        "print(f\"\\nTokenizer ready with vocabulary size: {tokenizer.vocab_size}\")"
      ],
      "metadata": {
        "id": "dUyEeRITOHFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "21a35ad3802c4772ab9d5d7b48b7fde2",
            "518150ab35f7434893f01f947ac0470a",
            "19328187c6d84018b0c2a7f129e6f946",
            "95cb0a04482f4bb2aad8d7ed867a9a96",
            "2f442a105b654f2598db20593f685b94",
            "bb534db8f35d42118e42825215f19502",
            "3ad9e110f03e4cf790cbf0d828693080",
            "647a948d12d6439eacc0386bbfd10fcc",
            "a986c831ef9c4a968a93491e22fe29a5",
            "24e454b054244cff8cab45a26396a657",
            "145b8896c1e14e358f69da83bd665245"
          ]
        },
        "outputId": "5ad97884-2026-49ac-a175-1ee5640f33af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building word-level vocabulary...\n",
            "Analyzing text corpus...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing texts:   0%|          | 0/22814 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21a35ad3802c4772ab9d5d7b48b7fde2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary Statistics:\n",
            "Total unique words in corpus: 22814\n",
            "Words with frequency >= 2: 16235\n",
            "Final vocabulary size: 16239\n",
            "Most common words: ['.', 'په', 'د', '،', 'کې', 'مانا', 'جمله', 'استعمال', 'لغت', 'دی', 'او', 'له', 'ته', 'چې', 'نه', 'دو', 'دي', 'ډېر', 'کور', 'یو']\n",
            "Sample vocabulary: ['<pad>', '<sos>', '<eos>', '<unk>', '.', 'په', 'د', '،', 'کې', 'مانا', 'جمله', 'استعمال', 'لغت', 'دی', 'او', 'له', 'ته', 'چې', 'نه', 'دو']\n",
            "Frequency distribution: {'21690-21699': 1, '16280-16289': 1, '15630-15639': 1, '13890-13899': 1, '11990-11999': 1, '7920-7929': 1, '7700-7709': 1, '7620-7629': 1, '7340-7349': 1, '5030-5039': 1}\n",
            "\n",
            "Sample text: ژبه چي شی دو؟\n",
            "Encoded: tensor([  1, 137, 412, 155,  19,  43,   2,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0])\n",
            "Decoded: ژبه چي شی دو ؟\n",
            "\n",
            "Tokenizer ready with vocabulary size: 16239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Initialize Model\n",
        "model = SimpleTTSModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    d_model=config.D_MODEL,      # Use config parameter\n",
        "    n_heads=config.N_HEADS,      # Use config parameter\n",
        "    n_layers=config.N_LAYERS,    # Use config parameter\n",
        "    mel_dim=config.N_MELS\n",
        ").to(config.DEVICE)\n",
        "\n",
        "# Initialize optimizer and criterion\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
        "print(f\"Target mel length: {config.TARGET_MEL_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzWEQC8-uuBk",
        "outputId": "c37127ca-7369-4e52-ee4a-a7b2f05ca79e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 28,839,329\n",
            "Model vocabulary size: 16239\n",
            "Batch size: 2\n",
            "Target mel length: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Training Loop\n",
        "model_save_path = f\"{config.OUTPUT_DIR}/checkpoints/kokoro_pashto_mangal_paktika\"\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "print(f\"Starting training for Mangal Paktika accent\")\n",
        "print(f\"Model will be saved to: {model_save_path}\")\n",
        "print(f\"Training for 10 epochs with checkpoints every 500 steps\")\n",
        "\n",
        "best_loss = float('inf')\n",
        "training_losses = []\n",
        "global_step = 0\n",
        "\n",
        "# Add overall training progress bar for 10 epochs\n",
        "epochs_progress = tqdm(range(10), desc=\"Training Progress\", unit=\"epoch\")\n",
        "\n",
        "for epoch in epochs_progress:\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    successful_batches = 0\n",
        "\n",
        "    # Progress bar for batches\n",
        "    batch_progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}\", unit=\"batch\", leave=False)\n",
        "\n",
        "    for batch_idx, batch in enumerate(batch_progress):\n",
        "        if batch is None:\n",
        "            continue\n",
        "\n",
        "        mel_specs = batch['mel_specs'].to(config.DEVICE)\n",
        "        texts = batch['texts']\n",
        "\n",
        "        # Tokenize texts\n",
        "        text_tokens = []\n",
        "        for text in texts:\n",
        "            tokens = tokenizer.encode(text, max_length=config.MAX_TEXT_LENGTH)\n",
        "            text_tokens.append(tokens)\n",
        "\n",
        "        text_tokens = torch.stack(text_tokens).to(config.DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(text_tokens, mel_specs)\n",
        "\n",
        "        # Get dimensions and handle sequence mismatch\n",
        "        batch_size, mel_dim, model_seq_len = outputs['mel_output'].shape\n",
        "        target_batch_size, target_mel_dim, target_seq_len = mel_specs.shape\n",
        "\n",
        "        # Use minimum sequence length\n",
        "        min_seq_len = min(model_seq_len, target_seq_len)\n",
        "\n",
        "        if min_seq_len < 10:\n",
        "            continue\n",
        "\n",
        "        # Truncate to same length\n",
        "        model_output_adjusted = outputs['mel_output'][:, :, :min_seq_len]\n",
        "        mel_specs_adjusted = mel_specs[:, :, :min_seq_len]\n",
        "\n",
        "        try:\n",
        "            # Calculate loss\n",
        "            mel_loss = criterion(model_output_adjusted, mel_specs_adjusted)\n",
        "            duration_loss = torch.mean(torch.abs(outputs['durations']))\n",
        "            loss = mel_loss + 0.1 * duration_loss\n",
        "\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                continue\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            successful_batches += 1\n",
        "            global_step += 1\n",
        "\n",
        "            # Update batch progress\n",
        "            batch_progress.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Step': global_step\n",
        "            })\n",
        "\n",
        "            # Save checkpoint every 500 steps\n",
        "            if global_step % 500 == 0:\n",
        "                checkpoint_path = f\"{model_save_path}/checkpoint_step_{global_step}.pth\"\n",
        "                torch.save({\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'global_step': global_step,\n",
        "                    'loss': loss.item(),\n",
        "                    'tokenizer': tokenizer,\n",
        "                    'config': config\n",
        "                }, checkpoint_path)\n",
        "                tqdm.write(f\"Checkpoint saved at step {global_step} (loss: {loss.item():.4f})\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            continue\n",
        "\n",
        "    # Calculate epoch loss\n",
        "    if successful_batches > 0:\n",
        "        avg_epoch_loss = epoch_loss / successful_batches\n",
        "        training_losses.append(avg_epoch_loss)\n",
        "\n",
        "        # Update epochs progress bar\n",
        "        epochs_progress.set_postfix({\n",
        "            'Epoch Loss': f'{avg_epoch_loss:.4f}',\n",
        "            'Best Loss': f'{best_loss:.4f}',\n",
        "            'Steps': global_step\n",
        "        })\n",
        "\n",
        "        # Save best model\n",
        "        if avg_epoch_loss < best_loss:\n",
        "            best_loss = avg_epoch_loss\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'global_step': global_step,\n",
        "                'loss': avg_epoch_loss,\n",
        "                'tokenizer': tokenizer,\n",
        "                'config': config\n",
        "            }, f\"{model_save_path}/best_model.pth\")\n",
        "            tqdm.write(f\"Saved best model with loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "    # Save epoch checkpoint\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'global_step': global_step,\n",
        "        'loss': avg_epoch_loss if successful_batches > 0 else float('inf'),\n",
        "        'tokenizer': tokenizer,\n",
        "        'config': config,\n",
        "        'training_losses': training_losses\n",
        "    }, f\"{model_save_path}/epoch_{epoch+1}.pth\")\n",
        "\n",
        "print(\"Training completed!\")\n",
        "print(f\"Total steps: {global_step}\")\n",
        "print(f\"Best loss achieved: {best_loss:.4f}\")\n",
        "print(f\"Checkpoints saved in: {model_save_path}\")"
      ],
      "metadata": {
        "id": "Y-hWlHs3OJN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "a591274903ca485c9a628cec8e8ded49",
            "520f2587cb6748e68003891922863897",
            "235cb80d63364dcf86d24b9cbc075f02",
            "66b8c42d4d594d15806ef13d9e09b91c",
            "af4753da20644b07a23f7480d3d95af1",
            "e6bc610a8ddd42de8faa80e4a8e9bb27",
            "81655834adcf48049f09e5cc19fd16b9",
            "b5bc67cb0cb34bb9b1c37b4ef13e5af6",
            "3f5fffb8b8c04c9f85a225f045664530",
            "52c27a8a693b44819f2d32588dbb0312",
            "1cf9fc8430a247fa901349fa5f15aa77",
            "6a2551c4ba344f3895c08235801f0775",
            "0269cd2d99b44bcda0400a1c7bc1c05c",
            "e39b6f9de7ed46828a77cdc2125d9344",
            "e121545903fc47d988dc0562ff75c06e",
            "ef21564b5e4f4f51acc6b4cc2e096f45",
            "f392f3dd7ebb4450b6322cb02e04b515",
            "d66f8b509e2f48728d54dfd2ceedb74e",
            "40fdb29335244c11a48445995941f968",
            "b3c8e8585e8f41bfa775080af4547739",
            "64b3ecd01ff8469c9191ff210fed4f93",
            "897ed3873a1e404a850ea1b540b41376"
          ]
        },
        "outputId": "ff987d8c-bf09-41ef-edc1-8681979498ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for Mangal Paktika accent\n",
            "Model will be saved to: /content/drive/MyDrive/kokoro_pashto_models/checkpoints/kokoro_pashto_mangal_paktika\n",
            "Training for 10 epochs with checkpoints every 500 steps\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a591274903ca485c9a628cec8e8ded49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Progress:   0%|          | 0/10 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a2551c4ba344f3895c08235801f0775",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/11407 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at step 500 (loss: 19.9790)\n",
            "Checkpoint saved at step 1000 (loss: 21.2240)\n",
            "Checkpoint saved at step 1500 (loss: 31.3045)\n",
            "Checkpoint saved at step 2000 (loss: 35.4066)\n",
            "Checkpoint saved at step 2500 (loss: 27.8336)\n",
            "Checkpoint saved at step 3000 (loss: 23.6342)\n",
            "Checkpoint saved at step 3500 (loss: 19.3657)\n",
            "Checkpoint saved at step 4000 (loss: 29.9722)\n",
            "Checkpoint saved at step 4500 (loss: 40.4478)\n",
            "Checkpoint saved at step 5000 (loss: 16.0171)\n",
            "Checkpoint saved at step 5500 (loss: 19.0345)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Save Final Model and Training Info\n",
        "# Save final model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': config.NUM_EPOCHS,\n",
        "    'loss': training_losses[-1],\n",
        "    'tokenizer': tokenizer,\n",
        "    'config': config,\n",
        "    'training_losses': training_losses\n",
        "}, f\"{model_save_path}/final_model.pth\")\n",
        "\n",
        "# Save training log\n",
        "with open(f\"{model_save_path}/training_log.txt\", 'w') as f:\n",
        "    f.write(f\"Accent: Mangal Paktika\\n\")\n",
        "    f.write(f\"JSON file: {config.JSON_FILE}\\n\")\n",
        "    f.write(f\"Audio folder: {config.AUDIO_FOLDER}\\n\")\n",
        "    f.write(f\"Training samples: {len(dataset)}\\n\")\n",
        "    f.write(f\"Vocabulary size: {tokenizer.vocab_size}\\n\")\n",
        "    f.write(f\"Best loss: {best_loss:.4f}\\n\")\n",
        "    f.write(f\"Final loss: {training_losses[-1]:.4f}\\n\")\n",
        "    f.write(\"\\nTraining losses per epoch:\\n\")\n",
        "    for i, loss in enumerate(training_losses):\n",
        "        f.write(f\"Epoch {i+1}: {loss:.4f}\\n\")\n",
        "\n",
        "print(f\"Final model saved to: {model_save_path}/final_model.pth\")\n",
        "print(f\"Best loss achieved: {best_loss:.4f}\")"
      ],
      "metadata": {
        "id": "S3fKqA9zOL2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Load and Test Model (Optional)\n",
        "def load_trained_model(model_path):\n",
        "    checkpoint = torch.load(model_path, map_location=config.DEVICE)\n",
        "\n",
        "    # Recreate model\n",
        "    loaded_tokenizer = checkpoint['tokenizer']\n",
        "    test_model = SimpleTTSModel(\n",
        "        vocab_size=loaded_tokenizer.vocab_size,\n",
        "        d_model=512,\n",
        "        n_heads=8,\n",
        "        n_layers=6,\n",
        "        mel_dim=config.N_MELS\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_model.eval()\n",
        "\n",
        "    return test_model, loaded_tokenizer\n",
        "\n",
        "# Load the best model\n",
        "model_path = f\"{model_save_path}/best_model.pth\"\n",
        "if os.path.exists(model_path):\n",
        "    trained_model, trained_tokenizer = load_trained_model(model_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "    # Test with sample text\n",
        "    sample_text = \"سلام ورور\"  # Hello brother in Pashto\n",
        "    text_tokens = trained_tokenizer.encode(sample_text).unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = trained_model(text_tokens)\n",
        "        generated_mel = outputs['mel_output']\n",
        "        print(f\"Generated mel spectrogram shape: {generated_mel.shape}\")\n",
        "        print(\"Model inference test completed!\")\n",
        "\n",
        "print(\"\\nTraining script completed successfully!\")\n",
        "print(f\"All models saved in: {config.OUTPUT_DIR}\")\n",
        "print(\"Mangal Paktika accent model training completed!\")"
      ],
      "metadata": {
        "id": "ViW8zbNtOLrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Load and Test Model (Optional)\n",
        "def load_trained_model(model_path):\n",
        "    checkpoint = torch.load(model_path, map_location=config.DEVICE)\n",
        "\n",
        "    # Recreate model\n",
        "    loaded_tokenizer = checkpoint['tokenizer']\n",
        "    test_model = SimpleTTSModel(\n",
        "        vocab_size=loaded_tokenizer.vocab_size,\n",
        "        d_model=512,\n",
        "        n_heads=8,\n",
        "        n_layers=6,\n",
        "        mel_dim=config.N_MELS\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    test_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_model.eval()\n",
        "\n",
        "    return test_model, loaded_tokenizer\n",
        "\n",
        "# Load the best model\n",
        "model_path = f\"{model_save_path}/best_model.pth\"\n",
        "if os.path.exists(model_path):\n",
        "    trained_model, trained_tokenizer = load_trained_model(model_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "    # Test with sample text\n",
        "    sample_text = \"سلام ورور\"  # Hello brother in Pashto\n",
        "    text_tokens = trained_tokenizer.encode(sample_text).unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = trained_model(text_tokens)\n",
        "        generated_mel = outputs['mel_output']\n",
        "        print(f\"Generated mel spectrogram shape: {generated_mel.shape}\")\n",
        "        print(\"Model inference test completed!\")\n",
        "\n",
        "print(\"\\nTraining script completed successfully!\")\n",
        "print(f\"All models saved in: {config.OUTPUT_DIR}\")\n",
        "print(\"To train another speaker, change SPEAKER_INDEX in Cell 12 and run from Cell 13 onwards.\")\n"
      ],
      "metadata": {
        "id": "l6GvkK_6OSKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "952f6b22",
        "outputId": "49795213-7ab6-4515-a5cb-a688c0915ebe"
      },
      "source": [
        "# Explicitly uninstall and install a potentially more compatible NumPy version\n",
        "!pip uninstall numpy -y\n",
        "!pip install 'numpy<2'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m480.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "fc31cbd4e01b407c88fe5e510dd2d519"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Gw6j2Ep0nZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}